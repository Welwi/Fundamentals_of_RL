{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_typo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCcAJveiunChUyQ4ulXOxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Welwi/RL_typo/blob/master/RL_typo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEqdvGemP8Bs",
        "colab_type": "text"
      },
      "source": [
        "In this project, I am training a RL algorithm that will master two varying envs with varying complexity.\n",
        "\n",
        "ENV 1: Cartpole\n",
        "The goal is to balance a pole, portruding from a cart, in an upright position by only movign the base left or right. This is an env with a low-dimensional observation space.\n",
        "\n",
        "ENV2: Pong\n",
        "The goal is to beat the competition. The env has a high-dimensional observation space - learning directly from raw pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCezM37-SGV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "164237e8-aee5-46fc-b5b3-2124f2afaeac"
      },
      "source": [
        "\n",
        "!apt-get install -y xvfb python-opengl x11-utils > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay scikit-video > /dev/null 2>&1\n",
        "\n",
        "!pip install mitdeeplearning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mitdeeplearning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/3b/b9174b68dc10832356d02a2d83a64b43a24f1762c172754407d22fc8f960/mitdeeplearning-0.1.2.tar.gz (2.1MB)\n",
            "\r\u001b[K     |▏                               | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 1.8MB/s eta 0:00:02\r\u001b[K     |▌                               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 2.0MB/s eta 0:00:02\r\u001b[K     |█                               | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |███                             | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 993kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (4.41.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (0.17.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->mitdeeplearning) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->mitdeeplearning) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->mitdeeplearning) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->mitdeeplearning) (0.16.0)\n",
            "Building wheels for collected packages: mitdeeplearning\n",
            "  Building wheel for mitdeeplearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mitdeeplearning: filename=mitdeeplearning-0.1.2-cp36-none-any.whl size=2114586 sha256=72d686830db44979b62ac7ed8df5c10c7557401505de07c12d6e2274163e385d\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/e1/73/5f01c787621d8a3c857f59876c79e304b9b64db9ff5bd61b74\n",
            "Successfully built mitdeeplearning\n",
            "Installing collected packages: mitdeeplearning\n",
            "Successfully installed mitdeeplearning-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-QQGQA2TIL-",
        "colab_type": "text"
      },
      "source": [
        "## Steps of RL probs in general:\n",
        "1. Initialize the env and the agent: describe the different observations and actions the agent can make in the env.\n",
        "\n",
        "2. Define the agent's memory: this will enable the agent to remember its past actions, observations and rewards\n",
        "\n",
        "3. Define a reward function: describes the reward associated with an action or sequence of actions\n",
        "\n",
        "4. Define the learning algorithm: this is used to reinforce the agent's good behavior and discourage the bad behaviors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2GrwZ3YP7tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import base64, io, time, gym\n",
        "import IPython, functools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import mitdeeplearning as mdl"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B99XtJvdUH0T",
        "colab_type": "text"
      },
      "source": [
        "## PART 1: CARTPOLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIrE3x5JU2hY",
        "colab_type": "text"
      },
      "source": [
        "Gym is a toolkit that has several pre-defined environments for training and testing RL learning agents.\n",
        "\n",
        "In Cartpole, the pole starts upright and the goal is to prevent it from falling. A reward of +1 is given for every timestep that the pole remains upright.\n",
        "A reward of -1 is given if the the pole is more than 15 degrees from the vertical or if the cart moves more than 2.4 units from the center of the track."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-eOAk5PPbrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6de3a930-4cf1-41b7-b5b0-8b2b353f68d9"
      },
      "source": [
        "# Instantiating the cartpole env\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "env.seed(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-qrXGmeYCyk",
        "colab_type": "text"
      },
      "source": [
        "Observations that help define the env:\n",
        "1. cart position\n",
        "2. cart velocity\n",
        "3. pole angle\n",
        "4. pole rotation rate\n",
        "\n",
        "Actions that the agent can take:\n",
        "- The agent can move either right or left.\n",
        "\n",
        "This shows that this is a low-dimensional observation and action spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo7NiaNhV_xq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1496a76-ba92-4d46-fd52-9fb547d002b2"
      },
      "source": [
        "# Checking the size of the space\n",
        "n_observations = env.observation_space\n",
        "print('Env has observation space =', n_observations)\n",
        "\n",
        "# Checking the num of actions that the agent can take\n",
        "n_actions = env.action_space.n\n",
        "print('Num of possible actions that the agent can choose from =', n_actions)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Env has observation space = Box(4,)\n",
            "Num of possible actions that the agent can choose from = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C4MHuqffUOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c888ba2e-62e7-4d5f-f04a-7dcafc586daa"
      },
      "source": [
        "n_actions"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k27CIunnayPu",
        "colab_type": "text"
      },
      "source": [
        "### Defining the agent\n",
        "\n",
        "In RL, a deep neural network defines the agent.\n",
        "This network takes in an observation of the environment, and outputs the probability of taking each of the possible actions.\n",
        "Since this is a low dimensional observation space, we can use a simple feed forward NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsK2HjcNZEUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the carpole agent\n",
        "def create_carpole_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "                                      tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "                                      tf.keras.layers.Dense(units=n_actions, activation= None)\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "cartpole_model = create_carpole_model()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1qk2pYMgR41",
        "colab_type": "text"
      },
      "source": [
        "Defining a feed forward pass through the network (action function)\n",
        "\n",
        "- takes observations as inputs\n",
        "- does a forward pass through the model\n",
        "- outputs the agent action\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMmUy-vZfe8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(model, observation):\n",
        "\n",
        "  # adding the batch dimension to the observation\n",
        "  observation = np.expand_dims(observation, axis=0)\n",
        "\n",
        "  # passing the observation through the model\n",
        "  logits = model.predict(observation)\n",
        "\n",
        "  # pass the probabilities through softmax to get true probability\n",
        "  prob_weights = tf.nn.softmax(logits).numpy()\n",
        "\n",
        "  # random selection of an action from observation\n",
        "  action = np.random.choice(n_actions, size=1, p=prob_weights.flatten())[0]\n",
        "\n",
        "  return action"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGYuoOfR8MfQ",
        "colab_type": "text"
      },
      "source": [
        "## Agents Memory\n",
        "\n",
        "Unables agent to remember past actions, observations and rewards.\n",
        "\n",
        "In RL:\n",
        "- Training happens alongside the agent's acting in the env\n",
        "- Episode: sequence of actions that ends in a terminal state (pole falling or cart crashing)\n",
        "- The agent needs to remember all of the observations and actions for the episode to reinforce or punish the actions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6w6E6sdovPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory:\n",
        "  def __init__(self):\n",
        "    self.clear()\n",
        "\n",
        "  # reseting the memory buffer\n",
        "  def clear(self):\n",
        "    self.observations = []\n",
        "    self.actions = []\n",
        "    self.rewards = []\n",
        "\n",
        "  def add_to_memory(self, new_observation, new_action, new_reward):\n",
        "    self.observations.append(new_observation)\n",
        "    self.actions.append(new_action)\n",
        "    self.rewards.append(new_reward)\n",
        "\n",
        "memory = Memory()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGx-f6kCGy1x",
        "colab_type": "text"
      },
      "source": [
        "## Rewards function\n",
        "\n",
        "For this case, we are focusing on giving preference to rewards that happen now than in the future.\n",
        "\n",
        "To implement function:\n",
        "- initialize an array of zeros  with length of the number of time steps\n",
        "- fill it with the discounted reward values as we look through the rewards from the episode\n",
        "- To find out which actions are better - normalize the rewards using the mean and std of the rewards across the learning episode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNVKdniYFTOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to normalize the rewards\n",
        "def normalize(x):\n",
        "   \n",
        "   x -= np.mean(x)\n",
        "   x /= np.std(x)\n",
        "   return x.astype(np.float32)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h4jsuQTOnAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discount_rewards(rewards, gamma=0.95):\n",
        "\n",
        "  #initializing an array of zeros\n",
        "  discounted_rewards = np.zeros_like(rewards)\n",
        "\n",
        "  R = 0\n",
        "  for t in range(0, len(rewards)):\n",
        "    R = R*gamma + rewards[t]\n",
        "\n",
        "    discounted_rewards[t] = R\n",
        "\n",
        "    return normalize(discounted_rewards)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpRKAls9S5IC",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Learning algorithm\n",
        "\n",
        "For this exercise the focus is going to be policy gradient methods which aim to maximize the likelihood of actions that result in large rewards\n",
        "\n",
        "This can be done by scaling the probabilities by the associated rewards. This results in amplifying the likelihood of actions that result in large rewards.\n",
        "\n",
        "This means that to minimize the negative likelihood is equivalent to minimizing the negative log-likelihood which can be done using softmax cross entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQLLSfVSAU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss (logits, actions, rewards):\n",
        "\n",
        "  neg_logprob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits= logits,\n",
        "                                                               labels = actions)\n",
        "  loss = tf.reduce_mean(neg_logprob * rewards)\n",
        "\n",
        "  return loss\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl9ogtb1WjWo",
        "colab_type": "text"
      },
      "source": [
        "## Defining the training step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDMP4TmvSASA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, optimizer, observations, actions, discounted_rewards):\n",
        "\n",
        "  with tf.GradientTape():\n",
        "    logits = model(observations)\n",
        "\n",
        "    loss = compute_loss(logits, actions, discount_rewards)\n",
        "  \n",
        "  # backpropagation to minimize the loss\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27xT2MhWXSL6",
        "colab_type": "text"
      },
      "source": [
        "## Running the Cartpole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WojmBoNhSAPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# instantiating the cartpole agent\n",
        "cartpole_model = create_carpole_model()\n",
        "\n",
        "# to track progress\n",
        "smoothed_reward = mdl.util.LossHistory(smoothing_factor=0.9)\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel = 'Iterations', ylabel='Rewards')\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear()\n",
        "\n",
        "for i_episode in range(500):\n",
        "\n",
        "  plotter.plot(smoothed_reward.get())\n",
        "\n",
        "  # Restart the env\n",
        "  observation = env.reset()\n",
        "  memory.clear()\n",
        "\n",
        "  while True:\n",
        "    # using our obsrevation, choose an action and take it in the env\n",
        "    action = choose_action(cartpole_model, observation)\n",
        "    next_observation, reward, done, info = env.step(action)\n",
        "\n",
        "    # add to memory\n",
        "    memory.add_to_memory(observation, action, reward)\n",
        "\n",
        "    if done:\n",
        "      # determine total reward and keep a record of this\n",
        "      total_reward = sum(memory.rewards)\n",
        "      smoothed_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTuw8vfWSALE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb15758f-45cb-4a9a-ec90-dadb194dd7b6"
      },
      "source": [
        "1e-3"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQRmEPQHSAH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRllBXpmSAEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-QC8s9UR_z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL9ts6xfPTLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_rewards = [1,-1,-1,1,1,1,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A77ZJFdPcPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c92664ad-1d15-4ca2-c8a7-55f3c0107bab"
      },
      "source": [
        "disc_rewards = np.zeros_like(test_rewards)\n",
        "disc_rewards"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "282vfEqTPcM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "057014a9-d480-463f-8961-978ee151750a"
      },
      "source": [
        "# using the cum reward formula\n",
        "gamma = 0.95\n",
        "R = 0\n",
        "for t in range(0, len(test_rewards)):\n",
        "  print(t)\n",
        "  R = R*gamma + test_rewards[t]\n",
        "  print(R)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1.0\n",
            "1\n",
            "-0.050000000000000044\n",
            "2\n",
            "-1.0475\n",
            "3\n",
            "0.004874999999999963\n",
            "4\n",
            "1.0046312499999999\n",
            "5\n",
            "1.9543996874999998\n",
            "6\n",
            "0.8566797031249997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzV4TzTiPcJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqxtlYbvPcGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwgz60wxPcDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhCYRSdxov0e",
        "colab_type": "text"
      },
      "source": [
        "## Breaking it down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pj2RXPzlKSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resets the state of the env and returns an initial observation\n",
        "observation = env.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc7iHkkql9ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f9f870a-faf7-428e-921c-8be636d9f398"
      },
      "source": [
        "observation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03073904,  0.00145001, -0.03088818, -0.03131252])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYF3VDmUnGEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05576618-e95d-4b57-fd3d-07892332c727"
      },
      "source": [
        "observation.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pi3WyTymcMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding batch dimension to the obs\n",
        "observation = np.expand_dims(observation, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UDDOtwIm-9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41e8e5b1-ed2a-4a13-c6de-f3cb1d28e287"
      },
      "source": [
        "observation.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOPkbTp0l-O2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "664db347-1407-4a34-c553-6b445d445767"
      },
      "source": [
        "# passing obs through the model\n",
        "logits = cartpole_model(observation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6mWzrG7mO4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "496db20f-3db4-4e12-bcfc-cd859a9c4240"
      },
      "source": [
        "logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.00845183,  0.02072986]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG2rpdkPmn3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # pass the probabilities through softmax to get true probability\n",
        "  prob_weights = tf.nn.softmax(logits).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EDFnpO-muKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad98f7c4-4695-486d-fe34-bf3290a15c72"
      },
      "source": [
        "prob_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49270508, 0.5072949 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh09DrRXoRQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4e42126-001a-4466-e2a0-543010e54cb6"
      },
      "source": [
        "prob_weights.flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49270508, 0.5072949 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1-jqCOHoY1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed6ca6e4-91ac-4ada-da4e-c14966241d74"
      },
      "source": [
        "prob_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqFSOYgHobzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ae967ed-989f-42e4-8bf1-6422a970b521"
      },
      "source": [
        "prob_weights.flatten().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAnibykcmvxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action = np.random.choice(n_actions, size=1, p=prob_weights.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fEob4aYolUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e5ed57a-f222-4c4f-c00b-69f205163293"
      },
      "source": [
        "action"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGMsrE_komPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "958dde36-2a20-48a3-a2f7-d81692bc9255"
      },
      "source": [
        "action[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYDgstsAonog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action = np.random.choice(n_actions, size=1, p=prob_weights.flatten())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KApPaPI1tkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}